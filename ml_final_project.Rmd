---
title: "R Notebook"
output:
  html_document: default
  html_notebook: default
---

```{r libraries}
library(tidyverse, quietly = T)
library(caret, quietly = T)
library(randomForest, quietly = T)
```

```{r load data}
train_df <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")

test_df <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
```

## Cleaning the Data 

Remove variables that likely do not predict the outcome based on their descriptions in the code book. Remove variables that have NAs for 90 percent or more of their values. Remove variables that have variations near zero. 

```{r clean}
# Variables that are not likely predictors
train_df <- train_df[, -c(1:7)]

# Variables that have over 90% NAs
nas <- as.vector(which(colMeans(is.na(train_df)) >= .90, arr.ind = T))
train_df <- train_df[, -nas]

# Near zero values
nzv <- nearZeroVar(train_df)
train_df <- train_df[, -nzv]
```

Apply the same cleaning method to the testing dataframe. Note that the training dataset and testing datset have the same variables with the exception of the last one, which is `classe` in the training dataset and `problem_id` in the testing dataset.

```{r}
# Variables that are not likely predictors
test_df <- test_df[, -c(1:7)]

# Variables that have over 90% NAs
test_df <- test_df[, -nas]

# Near zero values
test_df <- test_df[, -nzv]
```

We'll use the `train_df` dataset to build training, testing, and validation datasets. 

```{r split training df}
set.seed(1)

build <- createDataPartition(train_df$classe, p = .70, list = F)
validation <- train_df[-build, ]
build_data <- train_df[build, ]

in_training <- createDataPartition(build_data$classe, p = .70, list = F)
training <- build_data[in_training, ]
testing <- build_data[-in_training, ]
```

## Exploration 

```{r}
ggplot(data = training, aes(x = classe)) + 
  geom_histogram(stat = "count")
```

```{r}
ggplot(data = training, aes(x = total_accel_belt, y = total_accel_arm, color = classe)) + 
  geom_point(alpha = .5, size = 2)
```

## How the Model Was Built

## Cross Validation 

## Random Forest Model

```{r}
fit_rf <- randomForest(classe ~ ., data = training) 
```

```{r}
confusionMatrix(predict(fit_rf, testing), testing$classe)
```

Create a vector of predicted values using this model and the testing dataframe as it's input. 

```{r}
data.frame(number = c(1:20), pred = predict(fit_rf, test_df))
```

## Expected Out of Sample Error 

## Predictions on Test Cases